{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Source: UCI Machine Learning Repository\n",
    "- Th√®me: Pr√©diction d'abandon scolaire et r√©ussite acad√©mique\n",
    "- √âtablissement: Enseignement sup√©rieur au Portugal\n",
    "- URL: https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tools import count_outliers_iqr, prepare_feature_engineering, print_dataset_summary\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "\n",
    "# Palette de couleurs pour √©viter les warnings\n",
    "BINARY_TARGET_COLORS = [\"#e74c3c\", \"#2ecc71\"]\n",
    "BINARY_TARGET_ORDER = [\"Dropout\", \"Non-Dropout\"]\n",
    "MAP_BINARY_TARGET_COLORS = dict(zip(BINARY_TARGET_ORDER, BINARY_TARGET_COLORS))\n",
    "\n",
    "TERNARY_TARGET_COLORS = [\"#66c2a5\", \"#fc8d62\", \"#8da0cb\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/dataset.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Taille du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nombre d'observations: {df.shape[0]:,}\")\n",
    "print(f\"Nombre de variables: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Liste des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Typage des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Description du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Distribution de la variable cible (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df[\"Target\"].value_counts()\n",
    "\n",
    "result = (\n",
    "    df[\"Target\"]\n",
    "    .value_counts()\n",
    "    .to_frame(name=\"count\")\n",
    "    .assign(percentage=lambda x: x[\"count\"] / x[\"count\"].sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "explode = (0.05, 0.05, 0.05)  # L√©g√®re s√©paration des parts\n",
    "\n",
    "plt.pie(\n",
    "    target_counts.values,\n",
    "    labels=target_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=TERNARY_TARGET_COLORS,\n",
    "    explode=explode,\n",
    "    shadow=True,\n",
    "    textprops={\"fontsize\": 12, \"weight\": \"bold\"},\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution de la variable cible (Target)\", fontsize=14, weight=\"bold\", pad=20)\n",
    "\n",
    "plt.axis(\"equal\")  # Pour avoir un cercle parfait\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Premieres lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Nombre d'√©tudiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Classification Binaire: Dropout vs Non-Dropout\n",
    "--> Non-Dropout = Enrolled + Graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une nouvelle variable binaire\n",
    "df[\"Dropout_Binary\"] = df[\"Target\"].apply(lambda x: \"Dropout\" if x == \"Dropout\" else \"Non-Dropout\")\n",
    "\n",
    "# Calculer les proportions\n",
    "binary_counts = df[\"Dropout_Binary\"].value_counts()\n",
    "binary_pct = df[\"Dropout_Binary\"].value_counts(normalize=True)\n",
    "\n",
    "result = (\n",
    "    df[\"Dropout_Binary\"]\n",
    "    .value_counts()\n",
    "    .to_frame(name=\"count\")\n",
    "    .assign(percentage=lambda x: x[\"count\"] / x[\"count\"].sum())\n",
    ")\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Composition de 'Non-Dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dropout_detail = df[df[\"Dropout_Binary\"] == \"Non-Dropout\"][\"Target\"]\n",
    "result = (\n",
    "    non_dropout_detail.value_counts()\n",
    "    .to_frame(name=\"count\")\n",
    "    .assign(percentage=lambda x: x[\"count\"] / x[\"count\"].sum())\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Comparaison d'une classification binaire vs ternaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation: Dropout vs Non-Dropout avec pie chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Graphique 1: Distribution binaire\n",
    "colors_binary = [\"#e74c3c\", \"#2ecc71\"]  # Rouge pour Dropout, Vert pour Non-Dropout\n",
    "explode_binary = (0.1, 0)  # Faire ressortir Dropout\n",
    "\n",
    "axes[0].pie(\n",
    "    binary_counts.values,\n",
    "    labels=binary_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=colors_binary,\n",
    "    explode=explode_binary,\n",
    "    shadow=True,\n",
    "    textprops={\"fontsize\": 12, \"weight\": \"bold\"},\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Classification Binaire\\nDropout vs Non-Dropout\", fontsize=14, weight=\"bold\")\n",
    "\n",
    "# Graphique 2: Distribution originale (rappel)\n",
    "colors_original = [\"#66c2a5\", \"#fc8d62\", \"#8da0cb\"]\n",
    "target_counts = df[\"Target\"].value_counts()\n",
    "explode_original = (0.05, 0.05, 0.05)\n",
    "\n",
    "axes[1].pie(\n",
    "    target_counts.values,\n",
    "    labels=target_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=TERNARY_TARGET_COLORS,\n",
    "    explode=explode_original,\n",
    "    shadow=True,\n",
    "    textprops={\"fontsize\": 12, \"weight\": \"bold\"},\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Classification Multi-classe\\n(Original)\", fontsize=14, weight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComparaison:\")\n",
    "print(\n",
    "    f\"- Approche binaire: {binary_pct['Dropout']:.2%} Dropout vs {binary_pct['Non-Dropout']:.2%} Non-Dropout\"\n",
    ")\n",
    "print(f\"- Ratio de d√©s√©quilibre: 1:{binary_counts['Non-Dropout'] / binary_counts['Dropout']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Phase 2 : Qualit√© des Donn√©es\n",
    "\n",
    "Avant d'analyser les relations entre variables, v√©rifions la qualit√© de nos donn√©es :\n",
    "1. **Valeurs manquantes** - Y a-t-il des donn√©es absentes ?\n",
    "2. **Doublons** - Des lignes sont-elles dupliqu√©es ?\n",
    "3. **Outliers** - Des valeurs aberrantes existent-elles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 2.1 Analyse des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = (\n",
    "    df.isnull()\n",
    "    .sum()\n",
    "    .to_frame(name=\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: (x[\"missing_count\"] / len(df) * 100).round(2))\n",
    ")\n",
    "\n",
    "missing[missing[\"missing_count\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 2.2 Analyse des valeurs dupliqu√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons complets (toutes les colonnes identiques)\n",
    "duplicates_full = df.duplicated().sum()\n",
    "duplicates_pct = duplicates_full / len(df)\n",
    "print(f\"Duplicates: {duplicates_full} ({duplicates_pct:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## D√©tection des outliers - Variables num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des variables num√©riques principales\n",
    "numeric_cols = [\n",
    "    \"Age at enrollment\",\n",
    "    \"Admission grade\",\n",
    "    \"Previous qualification (grade)\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "]\n",
    "\n",
    "# Cr√©ation des boxplots avec seaborn (√©vite les warnings)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"Dropout_Binary\",\n",
    "        y=col,\n",
    "        hue=\"Dropout_Binary\",\n",
    "        hue_order=BINARY_TARGET_ORDER,\n",
    "        palette=BINARY_TARGET_COLORS,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(col, fontsize=11, weight=\"bold\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Valeur\")\n",
    "\n",
    "# Supprimer le dernier subplot vide\n",
    "axes[-1].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Boxplots des Variables Num√©riques Cl√©s\\n(Comparaison Dropout vs Non-Dropout)\",\n",
    "    fontsize=14,\n",
    "    weight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpr√©tation des boxplots:\")\n",
    "print(\"- Comparez les m√©dianes (ligne horizontale) entre Dropout et Non-Dropout\")\n",
    "print(\"- Des diff√©rences marqu√©es sugg√®rent un pouvoir pr√©dictif de la variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Outlier -> IQR\n",
    "\n",
    "- Uniquement sur les variables continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables CONTINUES uniquement (exclure les cat√©gorielles encod√©es en num√©rique)\n",
    "continuous_cols = [\n",
    "    \"Age at enrollment\",\n",
    "    \"Admission grade\",\n",
    "    \"Previous qualification (grade)\",\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "    \"Unemployment rate\",\n",
    "    \"Inflation rate\",\n",
    "    \"GDP\",\n",
    "]\n",
    "\n",
    "# Variables cat√©gorielles exclues (m√™me si encod√©es en num√©rique)\n",
    "categorical_excluded = [\n",
    "    \"Marital status\",\n",
    "    \"Application mode\",\n",
    "    \"Application order\",\n",
    "    \"Course\",\n",
    "    \"Daytime/evening attendance\",\n",
    "    \"Previous qualification\",\n",
    "    \"Nacionality\",\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\",\n",
    "    \"Displaced\",\n",
    "    \"Educational special needs\",\n",
    "    \"Debtor\",\n",
    "    \"Tuition fees up to date\",\n",
    "    \"Gender\",\n",
    "    \"Scholarship holder\",\n",
    "    \"International\",\n",
    "]\n",
    "\n",
    "print(f\"Analyse de {len(continuous_cols)} variables continues\")\n",
    "print(f\"Attention: Variables cat√©gorielles exclues: {len(categorical_excluded)}\\n\")\n",
    "\n",
    "outlier_summary = []\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        count, lower, upper = count_outliers_iqr(df, col)\n",
    "        pct = (count / len(df)) * 100\n",
    "        if count > 0:\n",
    "            outlier_summary.append(\n",
    "                {\n",
    "                    \"Variable\": col,\n",
    "                    \"Outliers\": count,\n",
    "                    \"Pourcentage\": f\"{pct:.2f}%\",\n",
    "                    \"Borne inf\": f\"{lower:.2f}\",\n",
    "                    \"Borne sup\": f\"{upper:.2f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "outlier_df = outlier_df.sort_values(\"Outliers\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Phase 3 : Analyse Bivari√©e - Variables Num√©riques vs Dropout\n",
    "\n",
    "**Objectif** : Identifier quelles variables num√©riques diff√©rencient les √©tudiants qui abandonnent de ceux qui r√©ussissent.\n",
    "\n",
    "**Questions cl√©s** :\n",
    "- Les Dropout ont-ils des notes d'admission plus faibles ?\n",
    "- L'√¢ge est-il un facteur de risque ?\n",
    "- La performance au 1er semestre pr√©dit-elle l'abandon ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Notes d'admission vs Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Admission grade\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"Dropout_Binary\",\n",
    "    y=\"Admission grade\",\n",
    "    hue=\"Dropout_Binary\",\n",
    "    hue_order=BINARY_TARGET_ORDER,\n",
    "    palette=BINARY_TARGET_COLORS,\n",
    "    legend=False,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Note d'admission par groupe\", fontsize=12, weight=\"bold\")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_ylabel(\"Note d'admission (0-200)\")\n",
    "\n",
    "# Previous qualification grade\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"Dropout_Binary\",\n",
    "    y=\"Previous qualification (grade)\",\n",
    "    hue=\"Dropout_Binary\",\n",
    "    hue_order=BINARY_TARGET_ORDER,\n",
    "    palette=BINARY_TARGET_COLORS,\n",
    "    legend=False,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Note de qualification ant√©rieure par groupe\", fontsize=12, weight=\"bold\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[1].set_ylabel(\"Note qualification (0-200)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Stats comparatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Admission grade\", \"Previous qualification (grade)\"]:\n",
    "    dropout_df = df[df[\"Dropout_Binary\"] == \"Dropout\"]\n",
    "    non_dropout_df = df[df[\"Dropout_Binary\"] == \"Non-Dropout\"]\n",
    "\n",
    "    dropout_mean = dropout_df[col].mean()\n",
    "    non_dropout_mean = non_dropout_df[col].mean()\n",
    "    diff = non_dropout_mean - dropout_mean\n",
    "    print(f\"\\n   {col}:\")\n",
    "    print(f\"- Dropout:     {dropout_mean:.1f}\")\n",
    "    print(f\"- Non-Dropout: {non_dropout_mean:.1f}\")\n",
    "    print(f\"- Diff√©rence:  {diff:+.1f} points ({'Significatif' if abs(diff) > 5 else 'Faible'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### √Çge √† l'inscription vs Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"Dropout_Binary\",\n",
    "    y=\"Age at enrollment\",\n",
    "    hue=\"Dropout_Binary\",\n",
    "    hue_order=BINARY_TARGET_ORDER,\n",
    "    palette=BINARY_TARGET_COLORS,\n",
    "    legend=False,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Distribution de l'√¢ge par groupe\", fontsize=12, weight=\"bold\")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_ylabel(\"√Çge √† l'inscription\")\n",
    "\n",
    "# Histogramme superpos√©\n",
    "for label, color in [(\"Dropout\", \"#e74c3c\"), (\"Non-Dropout\", \"#2ecc71\")]:\n",
    "    subset = df[df[\"Dropout_Binary\"] == label][\"Age at enrollment\"]\n",
    "    axes[1].hist(subset, bins=30, alpha=0.6, label=label, color=color, density=True)\n",
    "\n",
    "axes[1].set_title(\"Distribution de l'√¢ge (densit√©)\", fontsize=12, weight=\"bold\")\n",
    "axes[1].set_xlabel(\"√Çge √† l'inscription\")\n",
    "axes[1].set_ylabel(\"Densit√©\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "age_stats = (\n",
    "    df.groupby(\"Dropout_Binary\")[\"Age at enrollment\"]\n",
    "    .agg(\n",
    "        mean_age=\"mean\",\n",
    "        median_age=\"median\",\n",
    "        min_age=\"min\",\n",
    "        max_age=\"max\",\n",
    "    )\n",
    "    .round({\"mean_age\": 1})\n",
    ")\n",
    "\n",
    "display(age_stats)\n",
    "\n",
    "age_diff = age_stats.loc[\"Dropout\", \"mean_age\"] - age_stats.loc[\"Non-Dropout\", \"mean_age\"]\n",
    "interpretation = (\n",
    "    f\"Les √©tudiants en dropout sont en moyenne \"\n",
    "    f\"{abs(age_diff):.1f} ans \"\n",
    "    f\"{'plus √¢g√©s' if age_diff > 0 else 'plus jeunes'} \"\n",
    "    f\"que les √©tudiants non-dropout.\"\n",
    ")\n",
    "\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Performance 1er Semestre vs Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem1_cols = [\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, col in enumerate(sem1_cols):\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"Dropout_Binary\",\n",
    "        y=col,\n",
    "        hue=\"Dropout_Binary\",\n",
    "        hue_order=BINARY_TARGET_ORDER,\n",
    "        palette=BINARY_TARGET_COLORS,\n",
    "        legend=False,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    # Titre simplifi√©\n",
    "    short_name = col.replace(\"Curricular units 1st sem \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    axes[i].set_title(f\"1er Sem: {short_name.capitalize()}\", fontsize=11, weight=\"bold\")\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Variables du 1er Semestre - Comparaison Dropout vs Non-Dropout\",\n",
    "    fontsize=13,\n",
    "    weight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques cl√©s\n",
    "print(\"\\nüìà Statistiques du 1er semestre:\")\n",
    "key_col = \"Curricular units 1st sem (approved)\"\n",
    "dropout_val = df[df[\"Dropout_Binary\"] == \"Dropout\"][key_col].mean()\n",
    "non_dropout_val = df[df[\"Dropout_Binary\"] == \"Non-Dropout\"][key_col].mean()\n",
    "\n",
    "print(\"\\n   Unit√©s valid√©es au 1er semestre:\")\n",
    "print(f\"- Dropout:     {dropout_val:.2f} unit√©s en moyenne\")\n",
    "print(f\"- Non-Dropout: {non_dropout_val:.2f} unit√©s en moyenne\")\n",
    "print(\n",
    "    f\"- Ratio:       {non_dropout_val / max(dropout_val, 0.01):.1f}x plus d'unit√©s valid√©es pour Non-Dropout\"\n",
    ")\n",
    "\n",
    "key_col2 = \"Curricular units 1st sem (grade)\"\n",
    "dropout_grade = df[df[\"Dropout_Binary\"] == \"Dropout\"][key_col2].mean()\n",
    "non_dropout_grade = df[df[\"Dropout_Binary\"] == \"Non-Dropout\"][key_col2].mean()\n",
    "print(\"\\n   Note moyenne au 1er semestre:\")\n",
    "print(f\"- Dropout:     {dropout_grade:.2f}/20\")\n",
    "print(f\"- Non-Dropout: {non_dropout_grade:.2f}/20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Performance 2√®me Semestre vs Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem2_cols = [\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, col in enumerate(sem2_cols):\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"Dropout_Binary\",\n",
    "        y=col,\n",
    "        hue=\"Dropout_Binary\",\n",
    "        hue_order=BINARY_TARGET_ORDER,\n",
    "        palette=BINARY_TARGET_COLORS,\n",
    "        legend=False,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    short_name = col.replace(\"Curricular units 2nd sem \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    axes[i].set_title(f\"2√®me Sem: {short_name.capitalize()}\", fontsize=11, weight=\"bold\")\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Variables du 2√®me Semestre - Comparaison Dropout vs Non-Dropout\",\n",
    "    fontsize=13,\n",
    "    weight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparaison 1er vs 2√®me semestre\n",
    "print(\"\\nüìà Comparaison √©volution entre semestres:\")\n",
    "print(\"\\n   | Groupe       | Sem 1 (approved) | Sem 2 (approved) | √âvolution |\")\n",
    "print(\"   |--------------|------------------|------------------|-----------|\")\n",
    "\n",
    "for group in BINARY_TARGET_ORDER:\n",
    "    sem1_mean = df[df[\"Dropout_Binary\"] == group][\"Curricular units 1st sem (approved)\"].mean()\n",
    "    sem2_mean = df[df[\"Dropout_Binary\"] == group][\"Curricular units 2nd sem (approved)\"].mean()\n",
    "    evolution = sem2_mean - sem1_mean\n",
    "    print(f\"   | {group:12} | {sem1_mean:16.2f} | {sem2_mean:16.2f} | {evolution:+9.2f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Phase 3.2 : Variables Cat√©gorielles vs Dropout\n",
    "\n",
    "**Objectif** : Identifier quelles cat√©gories sont associ√©es √† un risque plus √©lev√© de Dropout.\n",
    "\n",
    "**Questions cl√©s** :\n",
    "- Certains programmes ont-ils plus d'abandons ?\n",
    "- Les boursiers abandonnent-ils moins ?\n",
    "- Le genre, l'√©tat civil ou les cours du soir influencent-ils le Dropout ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### On check les variables binaires vs Dropout + Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables binaires √† analyser\n",
    "binary_vars = [\n",
    "    (\"Gender\", {0: \"Femme\", 1: \"Homme\"}),\n",
    "    (\"Scholarship holder\", {0: \"Non boursier\", 1: \"Boursier\"}),\n",
    "    (\"Debtor\", {0: \"Non d√©biteur\", 1: \"D√©biteur\"}),\n",
    "    (\"Tuition fees up to date\", {0: \"Non √† jour\", 1: \"√Ä jour\"}),\n",
    "    (\"Displaced\", {0: \"Local\", 1: \"D√©plac√©\"}),\n",
    "    (\"International\", {0: \"National\", 1: \"International\"}),\n",
    "]\n",
    "\n",
    "# Calculer le taux de dropout pour chaque variable\n",
    "results = []\n",
    "for var, labels in binary_vars:\n",
    "    for val, label in labels.items():\n",
    "        subset = df[df[var] == val]\n",
    "        total = len(subset)\n",
    "        dropout_count = len(subset[subset[\"Dropout_Binary\"] == \"Dropout\"])\n",
    "        dropout_rate = (dropout_count / total * 100) if total > 0 else 0\n",
    "        results.append(\n",
    "            {\n",
    "                \"Variable\": var,\n",
    "                \"Cat√©gorie\": label,\n",
    "                \"Total\": total,\n",
    "                \"Dropout\": dropout_count,\n",
    "                \"Taux Dropout (%)\": round(dropout_rate, 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Quels facteurs augmentent le risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, labels in binary_vars:\n",
    "    rates = results_df[results_df[\"Variable\"] == var][\"Taux Dropout (%)\"].values\n",
    "    if len(rates) == 2 and abs(rates[0] - rates[1]) > 5:\n",
    "        higher = labels[0] if rates[0] > rates[1] else labels[1]\n",
    "        diff = abs(rates[0] - rates[1])\n",
    "        print(f\"- {var}: '{higher}' ‚Üí +{diff:.1f}% de dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Le petit graph qui va avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables binaires (sans Daytime/evening attendance)\n",
    "binary_vars_simple = [\n",
    "    \"Gender\",\n",
    "    \"Scholarship holder\",\n",
    "    \"Debtor\",\n",
    "    \"Tuition fees up to date\",\n",
    "    \"Displaced\",\n",
    "    \"International\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(binary_vars_simple):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Calculer les pourcentages\n",
    "    cross_tab = pd.crosstab(df[var], df[\"Dropout_Binary\"], normalize=\"index\") * 100\n",
    "\n",
    "    # Plot\n",
    "    cross_tab.plot(kind=\"bar\", ax=ax, color=[\"#2ecc71\", \"#e74c3c\"], edgecolor=\"black\")\n",
    "    ax.set_title(f\"{var}\", fontsize=11, weight=\"bold\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Pourcentage (%)\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    ax.legend([\"Non-Dropout\", \"Dropout\"], loc=\"upper right\")\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # Ajouter la ligne de r√©f√©rence (taux global)\n",
    "    global_dropout_rate = (df[\"Dropout_Binary\"] == \"Dropout\").mean() * 100\n",
    "    ax.axhline(\n",
    "        y=global_dropout_rate,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.5,\n",
    "        label=\"Taux global\",\n",
    "    )\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Taux de Dropout vs Non-Dropout par Variable Binaire\",\n",
    "    fontsize=14,\n",
    "    weight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Taux de dropout global: {global_dropout_rate:.1f}%\")\n",
    "print(\"   (Ligne rouge pointill√©e = r√©f√©rence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Programme d'√©tudes vs Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des codes de programme\n",
    "course_mapping = {\n",
    "    33: \"Biofuel Production\",\n",
    "    171: \"Animation & Multimedia\",\n",
    "    8014: \"Social Service (soir)\",\n",
    "    9003: \"Agronomy\",\n",
    "    9070: \"Communication Design\",\n",
    "    9085: \"Veterinary Nursing\",\n",
    "    9119: \"Informatics Engineering\",\n",
    "    9130: \"Equinculture\",\n",
    "    9147: \"Management\",\n",
    "    9238: \"Social Service\",\n",
    "    9254: \"Tourism\",\n",
    "    9500: \"Nursing\",\n",
    "    9556: \"Oral Hygiene\",\n",
    "    9670: \"Advertising & Marketing\",\n",
    "    9773: \"Journalism & Communication\",\n",
    "    9853: \"Basic Education\",\n",
    "    9991: \"Management (soir)\",\n",
    "}\n",
    "\n",
    "# Calculer le taux de dropout par programme\n",
    "course_stats = (\n",
    "    df.groupby(\"Course\")\n",
    "    .agg({\"Dropout_Binary\": lambda x: (x == \"Dropout\").sum(), \"Target\": \"count\"})\n",
    "    .rename(columns={\"Dropout_Binary\": \"Dropouts\", \"Target\": \"Total\"})\n",
    ")\n",
    "\n",
    "course_stats[\"Taux Dropout (%)\"] = (course_stats[\"Dropouts\"] / course_stats[\"Total\"] * 100).round(1)\n",
    "course_stats[\"Programme\"] = course_stats.index.map(course_mapping)\n",
    "course_stats = course_stats.sort_values(\"Taux Dropout (%)\", ascending=False)\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = [\n",
    "    \"#e74c3c\" if x > 40 else \"#f39c12\" if x > 30 else \"#2ecc71\"\n",
    "    for x in course_stats[\"Taux Dropout (%)\"]\n",
    "]\n",
    "\n",
    "bars = ax.barh(\n",
    "    course_stats[\"Programme\"],\n",
    "    course_stats[\"Taux Dropout (%)\"],\n",
    "    color=colors,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "ax.set_xlabel(\"Taux de Dropout (%)\", fontsize=12)\n",
    "ax.set_title(\"Taux de Dropout par Programme d'√âtudes\", fontsize=14, weight=\"bold\")\n",
    "ax.axvline(\n",
    "    x=global_dropout_rate,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"Moyenne ({global_dropout_rate:.1f}%)\",\n",
    ")\n",
    "ax.legend()\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, val in zip(bars, course_stats[\"Taux Dropout (%)\"]):\n",
    "    ax.text(\n",
    "        bar.get_width() + 0.5,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{val}%\",\n",
    "        va=\"center\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√©\n",
    "print(\"\\nüî¥ Programmes √† HAUT risque (>40% dropout):\")\n",
    "high_risk = course_stats[course_stats[\"Taux Dropout (%)\"] > 40]\n",
    "for _, row in high_risk.iterrows():\n",
    "    print(\n",
    "        f\"- {row['Programme']}: {row['Taux Dropout (%)']}% ({row['Dropouts']}/{row['Total']} √©tudiants)\"\n",
    "    )\n",
    "\n",
    "print(\"\\nüü¢ Programmes √† FAIBLE risque (<25% dropout):\")\n",
    "low_risk = course_stats[course_stats[\"Taux Dropout (%)\"] < 25]\n",
    "for _, row in low_risk.iterrows():\n",
    "    print(\n",
    "        f\"- {row['Programme']}: {row['Taux Dropout (%)']}% ({row['Dropouts']}/{row['Total']} √©tudiants)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Est-ce que le status marital joue ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des codes d'√©tat civil\n",
    "marital_mapping = {\n",
    "    1: \"C√©libataire\",\n",
    "    2: \"Mari√©(e)\",\n",
    "    3: \"Veuf/Veuve\",\n",
    "    4: \"Divorc√©(e)\",\n",
    "    5: \"Union de fait\",\n",
    "    6: \"S√©par√©(e)\",\n",
    "}\n",
    "\n",
    "# Calculer le taux de dropout par statut matrimonial\n",
    "marital_stats = (\n",
    "    df.groupby(\"Marital status\")\n",
    "    .agg({\"Dropout_Binary\": lambda x: (x == \"Dropout\").sum(), \"Target\": \"count\"})\n",
    "    .rename(columns={\"Dropout_Binary\": \"Dropouts\", \"Target\": \"Total\"})\n",
    ")\n",
    "\n",
    "marital_stats[\"Taux Dropout (%)\"] = (\n",
    "    marital_stats[\"Dropouts\"] / marital_stats[\"Total\"] * 100\n",
    ").round(1)\n",
    "marital_stats[\"Statut\"] = marital_stats.index.map(marital_mapping)\n",
    "marital_stats = marital_stats.sort_values(\"Taux Dropout (%)\", ascending=False)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1: Taux de dropout\n",
    "ax1 = axes[0]\n",
    "x_positions = range(len(marital_stats))\n",
    "colors = [\n",
    "    \"#e74c3c\" if x > global_dropout_rate else \"#2ecc71\" for x in marital_stats[\"Taux Dropout (%)\"]\n",
    "]\n",
    "bars1 = ax1.bar(x_positions, marital_stats[\"Taux Dropout (%)\"], color=colors, edgecolor=\"black\")\n",
    "ax1.axhline(y=global_dropout_rate, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "ax1.set_ylabel(\"Taux de Dropout (%)\")\n",
    "ax1.set_title(\"Taux de Dropout par Statut Matrimonial\", fontsize=12, weight=\"bold\")\n",
    "ax1.set_xticks(x_positions)\n",
    "ax1.set_xticklabels(marital_stats[\"Statut\"], rotation=45, ha=\"right\")\n",
    "\n",
    "# Graphique 2: Effectifs\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(x_positions, marital_stats[\"Total\"], color=\"steelblue\", edgecolor=\"black\")\n",
    "ax2.set_ylabel(\"Nombre d'√©tudiants\")\n",
    "ax2.set_title(\"Effectifs par Statut Matrimonial\", fontsize=12, weight=\"bold\")\n",
    "ax2.set_xticks(x_positions)\n",
    "ax2.set_xticklabels(marital_stats[\"Statut\"], rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau r√©capitulatif\n",
    "print(\"\\nüìã Tableau r√©capitulatif:\")\n",
    "display(marital_stats[[\"Statut\", \"Total\", \"Dropouts\", \"Taux Dropout (%)\"]].reset_index(drop=True))\n",
    "\n",
    "print(\n",
    "    f\"\\nüí° Note: La majorit√© des √©tudiants sont c√©libataires ({marital_stats[marital_stats['Statut'] == 'C√©libataire']['Total'].values[0]} sur {len(df)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Phase 4 : Analyse de Corr√©lation\n",
    "\n",
    "**Objectif** : Identifier les variables les plus corr√©l√©es au Dropout et d√©tecter les multicolin√©arit√©s.\n",
    "\n",
    "**Questions cl√©s** :\n",
    "- Quelles variables num√©riques sont les plus li√©es au Dropout ?\n",
    "- Y a-t-il des variables redondantes (fortement corr√©l√©es entre elles) ?\n",
    "- Quelles variables prioriser pour le machine learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Matrice de corr√©lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'une variable num√©rique pour Dropout (1 = Dropout, 0 = Non-Dropout)\n",
    "df[\"Dropout_Numeric\"] = (df[\"Dropout_Binary\"] == \"Dropout\").astype(int)\n",
    "\n",
    "# S√©lection des variables num√©riques pour la corr√©lation\n",
    "# On exclut les variables cat√©gorielles encod√©es en num√©rique\n",
    "numeric_for_corr = [\n",
    "    \"Dropout_Numeric\",  # Notre variable cible\n",
    "    \"Age at enrollment\",\n",
    "    \"Admission grade\",\n",
    "    \"Previous qualification (grade)\",\n",
    "    # Performance 1er semestre\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    # Performance 2√®me semestre\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "    # Indicateurs √©conomiques\n",
    "    \"Unemployment rate\",\n",
    "    \"Inflation rate\",\n",
    "    \"GDP\",\n",
    "]\n",
    "\n",
    "# Calcul de la matrice de corr√©lation\n",
    "corr_matrix = df[numeric_for_corr].corr()\n",
    "\n",
    "# Visualisation avec heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "# Masque pour la partie triangulaire sup√©rieure (√©vite les doublons)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "# Heatmap avec annotations\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdBu_r\",  # Rouge = corr√©lation n√©gative, Bleu = positive\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8, \"label\": \"Coefficient de corr√©lation\"},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    \"Matrice de Corr√©lation - Variables Num√©riques vs Dropout\\n(Triangle inf√©rieur)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpr√©tation de la heatmap :\")\n",
    "print(\"- Rouge fonc√© : Corr√©lation n√©gative forte (quand l'une augmente, l'autre diminue)\")\n",
    "print(\"- Bleu fonc√© : Corr√©lation positive forte (les deux augmentent ensemble)\")\n",
    "print(\"- Blanc/Clair : Pas de corr√©lation significative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### Correlation avec Dropout\n",
    "- Facteur de risque - augmente le dropout\n",
    "- Facteur protecteur - diminue le dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des corr√©lations avec notre variable cible\n",
    "# Tri par valeur absolue (pour voir les plus fortes, positives ou n√©gatives)\n",
    "# Affichage du Top 10\n",
    "print(\"Top 10 Variables les plus corr√©l√©es au Dropout\\n\")\n",
    "dropout_corr_top10 = (\n",
    "    corr_matrix[\"Dropout_Numeric\"]\n",
    "    .drop(\"Dropout_Numeric\")\n",
    "    .to_frame(name=\"correlation\")\n",
    "    .assign(abs_corr=lambda x: x[\"correlation\"].abs())\n",
    "    .sort_values(\"abs_corr\", ascending=False)\n",
    "    .head(10)\n",
    "    .assign(\n",
    "        direction=lambda x: x[\"correlation\"].apply(lambda v: \"risque\" if v > 0 else \"protecteur\"),\n",
    "    )\n",
    "    .drop(columns=\"abs_corr\")\n",
    ")\n",
    "\n",
    "display(dropout_corr_top10)\n",
    "\n",
    "# Extraction des corr√©lations avec notre variable cible\n",
    "dropout_corr = corr_matrix[\"Dropout_Numeric\"].drop(\"Dropout_Numeric\")\n",
    "\n",
    "# Tri par valeur absolue (pour voir les plus fortes, positives ou n√©gatives)\n",
    "dropout_corr_sorted = dropout_corr.reindex(dropout_corr.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Affichage du Top 10\n",
    "print(\"Top 10 Variables les plus corr√©l√©es au Dropout\\n\")\n",
    "for i, (var, corr) in enumerate(dropout_corr_sorted.head(10).items(), 1):\n",
    "    direction = \"‚¨ÜÔ∏è positive\" if corr > 0 else \"‚¨áÔ∏è n√©gative\"\n",
    "    print(f\"{i:2}. {var:<45} {corr:+.3f} ({direction})\")\n",
    "\n",
    "# Visualisation avec barplot horizontal\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = [\"#e74c3c\" if x > 0 else \"#2ecc71\" for x in dropout_corr_sorted.head(10)]\n",
    "bars = ax.barh(range(10), dropout_corr_sorted.head(10).values, color=colors)\n",
    "\n",
    "ax.set_yticks(range(10))\n",
    "ax.set_yticklabels(dropout_corr_sorted.head(10).index)\n",
    "ax.invert_yaxis()  # Top variables en haut\n",
    "ax.axvline(x=0, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlabel(\"Coefficient de Corr√©lation avec Dropout\")\n",
    "ax.set_title(\n",
    "    \"Top 10 Variables les Plus Corr√©l√©es au Dropout\\n(Rouge = augmente le Dropout, Vert = diminue le Dropout)\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Annotations sur les barres\n",
    "for bar, val in zip(bars, dropout_corr_sorted.head(10).values):\n",
    "    ax.text(\n",
    "        val + 0.02 if val > 0 else val - 0.02,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{val:+.3f}\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\" if val > 0 else \"right\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(dropout_corr_top10[dropout_corr_top10[\"correlation\"].abs() > 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### Synth√®se Phase 4 : Matrice de Corr√©lation\n",
    "\n",
    "**D√©couvertes cl√©s :**\n",
    "\n",
    "| Aspect | R√©sultat |\n",
    "|--------|----------|\n",
    "| **Pr√©dicteurs les plus forts** | Notes et unit√©s valid√©es du 2√®me semestre (r ‚âà -0.57) |\n",
    "| **Facteur de risque positif** | √Çge √† l'inscription (+0.254) - √©tudiants plus √¢g√©s |\n",
    "| **Indicateurs √©conomiques** | Faible corr√©lation avec le dropout (< 0.05) |\n",
    "| **Multicolin√©arit√© d√©tect√©e** | 11 paires avec \\|r\\| > 0.7 |\n",
    "\n",
    "**Implications pour le Machine Learning :**\n",
    "1. Les variables sem1 et sem2 sont fortement corr√©l√©es ‚Üí risque de redondance\n",
    "2. Prioriser les **grades** (notes) sur les autres m√©triques acad√©miques\n",
    "3. Le 2√®me semestre est plus pr√©dictif que le 1er\n",
    "4. L'√¢ge est un facteur de risque √† ne pas n√©gliger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## Phase 5 : Feature Engineering\n",
    "\n",
    "**Objectif** : Cr√©er de nouvelles variables pour am√©liorer la pr√©diction et r√©duire la multicolin√©arit√© d√©tect√©e en Phase 4.\n",
    "\n",
    "**Transformations pr√©vues :**\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| **Discr√©tisation** | √Çge ‚Üí tranches (17-20, 21-25, 26-35, 36+) |\n",
    "| **Regroupement** | Statut marital ‚Üí Solo/Couple |\n",
    "| **Regroupement** | Qualifications ‚Üí Secondaire/Sup√©rieur |\n",
    "| **Regroupement** | Programmes ‚Üí Domaines (Sant√©, Tech, Business...) |\n",
    "| **Ratios** | Taux de r√©ussite par semestre |\n",
    "| **Agr√©gations** | Notes moyennes, tendance de performance |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "### Discr√©tisation de l'√¢ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de la nouvelle variable\n",
    "df[\"Age_Group\"] = pd.cut(\n",
    "    df[\"Age at enrollment\"],\n",
    "    bins=[0, 20, 25, 35, 100],\n",
    "    labels=[\"17-20\", \"21-25\", \"26-35\", \"36+\"],\n",
    ")\n",
    "\n",
    "age_counts = df[\"Age_Group\"].value_counts(dropna=False)\n",
    "age_pct = df[\"Age_Group\"].value_counts(normalize=True, dropna=False)\n",
    "\n",
    "pd.concat([age_counts, age_pct], axis=1, keys=[\"count\", \"percentage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Taux de dropout par tranche d'age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_by_age = (\n",
    "    df.groupby(\"Age_Group\", observed=True)[\"Dropout_Binary\"]\n",
    "    .apply(lambda x: (x == \"Dropout\").mean() * 100)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution des tranches d'√¢ge\n",
    "colors = [\"#3498db\", \"#9b59b6\", \"#e67e22\", \"#e74c3c\"]\n",
    "ax1 = axes[0]\n",
    "age_dist = df[\"Age_Group\"].value_counts().sort_index()\n",
    "age_dist.plot(kind=\"bar\", ax=ax1, color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "ax1.set_title(\"Distribution des Tranches d'√Çge\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Tranche d'√¢ge\")\n",
    "ax1.set_ylabel(\"Nombre d'√©tudiants\")\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Ajouter les pourcentages sur les barres\n",
    "for i, (idx, val) in enumerate(age_dist.items()):\n",
    "    ax1.text(i, val + 50, f\"{val / len(df) * 100:.1f}%\", ha=\"center\", fontsize=10)\n",
    "\n",
    "# Taux de dropout par tranche\n",
    "ax2 = axes[1]\n",
    "colors_dropout = [\n",
    "    \"#2ecc71\" if r < 30 else \"#f39c12\" if r < 35 else \"#e74c3c\" for r in dropout_by_age\n",
    "]\n",
    "dropout_by_age.plot(kind=\"bar\", ax=ax2, color=colors_dropout, edgecolor=\"black\", alpha=0.8)\n",
    "ax2.axhline(\n",
    "    y=df[\"Dropout_Binary\"].apply(lambda x: x == \"Dropout\").mean() * 100,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Moyenne globale\",\n",
    ")\n",
    "ax2.set_title(\"Taux de Dropout par Tranche d'√Çge\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Tranche d'√¢ge\")\n",
    "ax2.set_ylabel(\"Taux de Dropout (%)\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "ax2.legend()\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for i, (idx, val) in enumerate(dropout_by_age.items()):\n",
    "    ax2.text(i, val + 1, f\"{val:.1f}%\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### Tableau r√©capitulatif des nouvelles features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## R√©capitulatif des nouvelles features cr√©√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des nouvelles features avec leurs statistiques\n",
    "new_categorial_features = [\"Age_Group\", \"Marital_Binary\", \"Education_Level\", \"Course_Domain\"]\n",
    "new_numerical_features = [\n",
    "    \"Success_Rate_Sem1\",\n",
    "    \"Success_Rate_Sem2\",\n",
    "    \"Avg_Grade\",\n",
    "    \"Total_Approved\",\n",
    "    \"Performance_Trend\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Variable Cat√©gorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in new_categorial_features:\n",
    "    dropout_rate = df.groupby(feat, observed=True)[\"Dropout_Binary\"].apply(\n",
    "        lambda x: (x == \"Dropout\").mean() * 100\n",
    "    )\n",
    "    max_rate = dropout_rate.max()\n",
    "    min_rate = dropout_rate.min()\n",
    "    spread = max_rate - min_rate\n",
    "    print(f\"  {feat}: √©cart {spread:.1f}% (min: {min_rate:.1f}%, max: {max_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### Variables num√©riques (corr√©lation avec Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in new_numerical_features:\n",
    "    corr = df[feat].corr(df[\"Dropout_Numeric\"])\n",
    "    effect = \"facteur de risque\" if corr > 0 else \"facteur protecteur\"\n",
    "    print(f\"  {feat}: r = {corr:+.3f} ({effect})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Synth√®se Phase 5 : Feature Engineering\n",
    "\n",
    "**9 nouvelles variables cr√©√©es** pour am√©liorer l'analyse et pr√©parer le Machine Learning.\n",
    "\n",
    "#### R√©sultats cl√©s :\n",
    "\n",
    "| Type de transformation | Meilleure feature | Impact sur Dropout |\n",
    "|------------------------|-------------------|-------------------|\n",
    "| **Discr√©tisation** | Age_Group | √âcart de 36.3% entre tranches |\n",
    "| **Regroupement cat√©goriel** | Course_Domain | √âcart de 34.7% entre domaines |\n",
    "| **Ratio de performance** | Success_Rate_Sem2 | r = -0.705 (le plus fort !) |\n",
    "| **Agr√©gation** | Avg_Grade | r = -0.551 |\n",
    "\n",
    "#### D√©couvertes importantes :\n",
    "\n",
    "1. **Le taux de r√©ussite est plus pr√©dictif que les notes brutes**\n",
    "   - `Success_Rate_Sem2` (r = -0.705) surpasse m√™me les notes individuelles\n",
    "   - Cela confirme l'importance du ratio approved/enrolled\n",
    "\n",
    "2. **Les domaines d'√©tudes r√©v√®lent des patterns clairs**\n",
    "   - Tech : 54.9% de dropout (risque tr√®s √©lev√©)\n",
    "   - Sant√© : 20.3% de dropout (protection forte)\n",
    "\n",
    "3. **Les regroupements simplifient sans perdre d'information**\n",
    "   - Solo vs Couple capture l'essentiel du statut marital\n",
    "   - Secondaire/Sup√©rieur est suffisant pour la qualification\n",
    "\n",
    "#### Recommandations pour le Modeling :\n",
    "\n",
    "‚úÖ **Variables √† privil√©gier** :\n",
    "- `Success_Rate_Sem2` (r = -0.705)\n",
    "- `Age_Group` (√©cart 36.3%)\n",
    "- `Course_Domain` (√©cart 34.7%)\n",
    "\n",
    "‚ùå **Variables redondantes √† √©viter** :\n",
    "- Ne pas utiliser √† la fois les notes ET les ratios\n",
    "- Choisir entre `Total_Approved` et `Success_Rate`\n",
    "\n",
    "---\n",
    "\n",
    "**L'EDA est maintenant complet !** Les donn√©es sont pr√™tes pour la phase de mod√©lisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## Phase 6 : Pr√©paration ML et Mod√©lisation\n",
    "\n",
    "**Objectif** : Pr√©parer les donn√©es et entra√Æner des mod√®les de classification pour pr√©dire le dropout.\n",
    "\n",
    "### Strat√©gie bas√©e sur l'EDA :\n",
    "| Aspect | D√©cision |\n",
    "|--------|----------|\n",
    "| **Features cl√©s** | Ratios de performance (`Success_Rate_Sem2` r=-0.705), agr√©gations |\n",
    "| **Exclusions** | Variables avec multicolin√©arit√© (grades individuels), indicateurs √©conomiques |\n",
    "| **D√©s√©quilibre** | ~32% Dropout ‚Üí utiliser `class_weight='balanced'` |\n",
    "| **M√©trique prioritaire** | **Recall** (ne pas manquer les √©tudiants √† risque) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Pr√©paration des features et target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_feature_engineering(df)\n",
    "\n",
    "# D√©finir les features selon le plan\n",
    "numeric_features = [\n",
    "    \"Success_Rate_Sem1\",\n",
    "    \"Success_Rate_Sem2\",\n",
    "    \"Avg_Grade\",\n",
    "    \"Total_Approved\",\n",
    "    \"Age at enrollment\",\n",
    "    \"Admission grade\",\n",
    "    \"Performance_Trend\",\n",
    "]\n",
    "\n",
    "# Features cat√©gorielles cr√©√©es pendant le Feature Engineering\n",
    "categorical_features = [\n",
    "    \"Age_Group\",\n",
    "    \"Course_Domain\",\n",
    "    \"Marital_Binary\",\n",
    "    \"Education_Level\",\n",
    "]\n",
    "\n",
    "# Features binaires (d√©j√† encod√©es 0/1)\n",
    "binary_features = [\n",
    "    \"Tuition fees up to date\",\n",
    "    \"Scholarship holder\",\n",
    "    \"Debtor\",\n",
    "    \"Gender\",\n",
    "    \"Displaced\",\n",
    "]\n",
    "\n",
    "# V√©rifier que toutes les features existent\n",
    "all_features = numeric_features + categorical_features + binary_features\n",
    "missing_cols = [col for col in all_features if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Colonnes manquantes : {missing_cols}\")\n",
    "else:\n",
    "    print(\"Toutes les features sont disponibles\")\n",
    "\n",
    "# Cr√©er X (features) et y (target binaire)\n",
    "X = df[all_features].copy()\n",
    "y = (df[\"Dropout_Binary\"] == \"Dropout\").astype(int)  # 1 = Dropout, 0 = Non-Dropout\n",
    "\n",
    "print(\"\\nDimensions:\")\n",
    "print(f\"  X : {X.shape}\")\n",
    "print(f\"  y : {y.shape}\")\n",
    "print(\"\\nDistribution du target:\")\n",
    "print(f\"  Dropout (1)     : {y.sum()} ({y.mean() * 100:.1f}%)\")\n",
    "print(f\"  Non-Dropout (0) : {len(y) - y.sum()} ({(1 - y.mean()) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "### V√©rification des valeurs manquantes \n",
    "- **Attention**: Success_Rate peuvent avoir des `NaN` (div/0 si enrolled=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = X.isnull().sum()\n",
    "missing_pct = (X.isnull().sum() / len(X)) * 100\n",
    "missing_df = pd.DataFrame({\"Manquantes\": missing, \"Pourcentage\": missing_pct})\n",
    "missing_df = missing_df[missing_df[\"Manquantes\"] > 0].sort_values(\"Manquantes\", ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "\n",
    "    # Strat√©gie : Imputer avec la m√©diane pour les variables num√©riques\n",
    "    # (les NaN signifient 0 unit√©s inscrites = √©tudiant probablement en difficult√©)\n",
    "    print(\"\\nStrat√©gie d'imputation : M√©diane pour les variables num√©riques\")\n",
    "\n",
    "    for col in missing_df.index:\n",
    "        if col in numeric_features:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "            print(f\"  {col}: NaN ‚Üí {median_val:.3f} (m√©diane)\")\n",
    "\n",
    "    print(\"\\nApr√®s imputation:\")\n",
    "    print(f\"  Valeurs manquantes restantes: {X.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"Aucune valeur manquante!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### Cr√©ation du pipeline + split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le preprocessor avec ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"),\n",
    "            categorical_features,\n",
    "        ),\n",
    "        (\"bin\", \"passthrough\", binary_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### Split Train/Test (stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split stratifi√© (pr√©serve les proportions de classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print_dataset_summary(\"Train\", X_train, y_train, len(X))\n",
    "print_dataset_summary(\"Test\", X_test, y_test, len(X))\n",
    "\n",
    "# V√©rifier que les proportions sont pr√©serv√©es\n",
    "print(\n",
    "    f\"\\nProportions pr√©serv√©es: Train {y_train.mean() * 100:.1f}% vs Test {y_test.mean() * 100:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### Mod√®le de base: La r√©gression logistique\n",
    "**Why ;-)**\n",
    "- Interpr√©table (coeff = importance des features)\n",
    "- Rapide √† entrainer\n",
    "- R√©f√©rence pour comparer avec d'autres mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le pipeline complet (pr√©traitement + mod√®le)\n",
    "baseline_model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                class_weight=\"balanced\",  # G√®re le d√©s√©quilibre des classes\n",
    "                max_iter=1000,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "y_pred_proba = baseline_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### Rapport de classification de la r√©gression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Dropout\", \"Dropout\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### M√©triques cl√©s (recall, f1-score, auc-roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©triques cl√©s\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\nM√©triques Prioritaires (classe Dropout):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Recall (Dropout)  : {recall:.3f} ‚≠ê (priorit√© : ne pas manquer les √† risque)\")\n",
    "print(f\"  F1-Score (Dropout): {f1:.3f}\")\n",
    "print(f\"  AUC-ROC           : {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matrice de confusion\n",
    "ax1 = axes[0]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Dropout\", \"Dropout\"])\n",
    "disp.plot(ax=ax1, cmap=\"Blues\", values_format=\"d\")\n",
    "ax1.set_title(\n",
    "    \"Matrice de Confusion\\n(Logistic Regression Baseline)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Courbe ROC\n",
    "ax2 = axes[1]\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred_proba, ax=ax2, color=\"#3498db\", lw=2)\n",
    "ax2.plot([0, 1], [0, 1], \"k--\", lw=1, label=\"Random (AUC=0.5)\")\n",
    "ax2.set_title(f\"Courbe ROC (AUC = {auc:.3f})\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpr√©tation de la matrice de confusion\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "## Rappel\n",
    "## Vrai n√©gatifs - TN: Non-dropout correctement identifi√©s (541)\n",
    "## Vrai positifs - TP: Dropout correctement identifi√©s (60)\n",
    "## Faux positifs - FP: Non-dropout class√©s Dropout (fausse alerte)\n",
    "## Faux n√©gatifs - FN: Dropout manqu√©s\n",
    "print(\n",
    "    f\"\\nüí° Sur {y_test.sum()} √©tudiants √† risque, le mod√®le en identifie {tp} ({tp / y_test.sum() * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Synth√®se Phase 6 : Mod√®le Baseline\n",
    "\n",
    "**R√©sultats du mod√®le Logistic Regression (Baseline)** :\n",
    "\n",
    "| M√©trique | Valeur | Interpr√©tation |\n",
    "|----------|--------|----------------|\n",
    "| **Recall (Dropout)** | 83.1% | Sur 284 √©tudiants √† risque, 236 sont identifi√©s |\n",
    "| **F1-Score (Dropout)** | 81.4% | Bon √©quilibre pr√©cision/rappel |\n",
    "| **AUC-ROC** | 93.1% | Excellente capacit√© de discrimination |\n",
    "| **Accuracy** | 87.8% | Performance globale |\n",
    "\n",
    "**Analyse des erreurs** :\n",
    "- **48 Faux N√©gatifs** : √âtudiants √† risque non d√©tect√©s (erreur critique ‚ùå)\n",
    "- **60 Faux Positifs** : Fausses alertes (co√ªt acceptable)\n",
    "\n",
    "**Conclusion** :\n",
    "Le mod√®le baseline Logistic Regression atteint d√©j√† des performances tr√®s satisfaisantes gr√¢ce :\n",
    "1. Aux features engineered (`Success_Rate_Sem2` avec r = -0.705)\n",
    "2. √Ä la gestion du d√©s√©quilibre via `class_weight='balanced'`\n",
    "3. √Ä un bon pr√©traitement (StandardScaler + OneHotEncoder)\n",
    "\n",
    "**Prochaines √©tapes sugg√©r√©es** :\n",
    "1. Tester d'autres mod√®les (Random Forest, XGBoost, etc.)\n",
    "2. Optimiser les hyperparam√®tres avec GridSearchCV\n",
    "3. Explorer SMOTE vs class_weight pour le d√©s√©quilibre\n",
    "4. Ajuster le seuil de d√©cision pour maximiser le Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "## Phase 6.2 : Comparaison de Mod√®les et Optimisation\n",
    "\n",
    "**Objectif** : Tester plusieurs algorithmes et optimiser le meilleur mod√®le.\n",
    "\n",
    "### Mod√®les √† comparer :\n",
    "| Niveau | Mod√®le | Caract√©ristiques |\n",
    "|--------|--------|------------------|\n",
    "| Baseline | Logistic Regression | D√©j√† fait (Recall=83.1%, AUC=93.1%) |\n",
    "| Interm√©diaire | Random Forest | Robuste, feature importance native |\n",
    "| Interm√©diaire | Gradient Boosting | Performant, g√®re bien le d√©s√©quilibre |\n",
    "| Interm√©diaire | SVM (RBF) | Bon pour donn√©es non-lin√©aires |\n",
    "| Avanc√© | XGBoost | √âtat de l'art, tr√®s performant |\n",
    "\n",
    "### Strat√©gie d'√©valuation :\n",
    "- **Cross-validation 5-fold stratifi√©e** pour comparer √©quitablement\n",
    "- **M√©trique principale** : F1-Score (√©quilibre pr√©cision/rappel)\n",
    "- **M√©trique secondaire** : Recall (ne pas manquer les dropouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### Comparaison de Mo√®les avec Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer scale_pos_weight pour XGBoost (ratio classe majoritaire/minoritaire)\n",
    "scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "\n",
    "# D√©finir les mod√®les √† comparer\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "        verbosity=0,\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(f\"\\nMod√®les √† comparer : {len(models)}\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.2 Cross-Validation 5-Fold Stratifi√©e\n",
    "# =============================================================================\n",
    "# Stratification : pr√©serve les proportions de classes dans chaque fold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Stocker les r√©sultats\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"F1 Mean\": [],\n",
    "    \"F1 Std\": [],\n",
    "    \"Recall Mean\": [],\n",
    "    \"Recall Std\": [],\n",
    "    \"AUC Mean\": [],\n",
    "    \"AUC Std\": [],\n",
    "}\n",
    "\n",
    "print(\"üîÑ Cross-validation en cours...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Cr√©er le pipeline pour chaque mod√®le\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "\n",
    "    # Calculer les scores\n",
    "    f1_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    recall_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"recall\", n_jobs=-1)\n",
    "    auc_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "    # Stocker les r√©sultats\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"F1 Mean\"].append(f1_scores.mean())\n",
    "    results[\"F1 Std\"].append(f1_scores.std())\n",
    "    results[\"Recall Mean\"].append(recall_scores.mean())\n",
    "    results[\"Recall Std\"].append(recall_scores.std())\n",
    "    results[\"AUC Mean\"].append(auc_scores.mean())\n",
    "    results[\"AUC Std\"].append(auc_scores.std())\n",
    "\n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    print(f\"   F1-Score : {f1_scores.mean():.3f} (¬±{f1_scores.std():.3f})\")\n",
    "    print(f\"   Recall   : {recall_scores.mean():.3f} (¬±{recall_scores.std():.3f})\")\n",
    "    print(f\"   AUC-ROC  : {auc_scores.mean():.3f} (¬±{auc_scores.std():.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Cross-validation termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.3 Tableau Comparatif des Mod√®les\n",
    "# =============================================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Trier par F1-Score\n",
    "results_df = results_df.sort_values(\"F1 Mean\", ascending=False)\n",
    "\n",
    "\n",
    "# Formater pour l'affichage\n",
    "def format_score(mean, std):\n",
    "    return f\"{mean:.3f} ¬±{std:.3f}\"\n",
    "\n",
    "\n",
    "display_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Mod√®le\": results_df[\"Model\"],\n",
    "        \"F1-Score\": [\n",
    "            format_score(m, s) for m, s in zip(results_df[\"F1 Mean\"], results_df[\"F1 Std\"])\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            format_score(m, s) for m, s in zip(results_df[\"Recall Mean\"], results_df[\"Recall Std\"])\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            format_score(m, s) for m, s in zip(results_df[\"AUC Mean\"], results_df[\"AUC Std\"])\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üìä Comparaison des Mod√®les (Cross-Validation 5-Fold)\")\n",
    "print(\"=\" * 70)\n",
    "display(display_df.reset_index(drop=True))\n",
    "\n",
    "# Identifier le meilleur mod√®le\n",
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_f1 = results_df.iloc[0][\"F1 Mean\"]\n",
    "best_recall = results_df.iloc[0][\"Recall Mean\"]\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le (F1-Score) : {best_model_name}\")\n",
    "print(f\"   F1 = {best_f1:.3f}, Recall = {best_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.4 Visualisation Comparative\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Pr√©parer les donn√©es pour les graphiques\n",
    "models_names = results_df[\"Model\"].tolist()\n",
    "colors = [\"#3498db\", \"#2ecc71\", \"#e74c3c\", \"#9b59b6\"]\n",
    "\n",
    "# Graphique 1: F1-Score\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(\n",
    "    models_names,\n",
    "    results_df[\"F1 Mean\"],\n",
    "    xerr=results_df[\"F1 Std\"],\n",
    "    color=colors,\n",
    "    alpha=0.8,\n",
    "    capsize=5,\n",
    ")\n",
    "ax1.set_xlabel(\"F1-Score\", fontsize=12)\n",
    "ax1.set_title(\"F1-Score par Mod√®le\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xlim(0.65, 0.85)\n",
    "for i, (v, s) in enumerate(zip(results_df[\"F1 Mean\"], results_df[\"F1 Std\"])):\n",
    "    ax1.text(v + s + 0.005, i, f\"{v:.3f}\", va=\"center\", fontsize=10)\n",
    "\n",
    "# Graphique 2: Recall\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(\n",
    "    models_names,\n",
    "    results_df[\"Recall Mean\"],\n",
    "    xerr=results_df[\"Recall Std\"],\n",
    "    color=colors,\n",
    "    alpha=0.8,\n",
    "    capsize=5,\n",
    ")\n",
    "ax2.set_xlabel(\"Recall\", fontsize=12)\n",
    "ax2.set_title(\"Recall (Dropout) par Mod√®le\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlim(0.65, 0.85)\n",
    "for i, (v, s) in enumerate(zip(results_df[\"Recall Mean\"], results_df[\"Recall Std\"])):\n",
    "    ax2.text(v + s + 0.005, i, f\"{v:.3f}\", va=\"center\", fontsize=10)\n",
    "\n",
    "# Graphique 3: AUC-ROC\n",
    "ax3 = axes[2]\n",
    "bars3 = ax3.barh(\n",
    "    models_names,\n",
    "    results_df[\"AUC Mean\"],\n",
    "    xerr=results_df[\"AUC Std\"],\n",
    "    color=colors,\n",
    "    alpha=0.8,\n",
    "    capsize=5,\n",
    ")\n",
    "ax3.set_xlabel(\"AUC-ROC\", fontsize=12)\n",
    "ax3.set_title(\"AUC-ROC par Mod√®le\", fontsize=14, fontweight=\"bold\")\n",
    "ax3.set_xlim(0.85, 0.95)\n",
    "for i, (v, s) in enumerate(zip(results_df[\"AUC Mean\"], results_df[\"AUC Std\"])):\n",
    "    ax3.text(v + s + 0.002, i, f\"{v:.3f}\", va=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation : Les performances sont tr√®s proches entre les mod√®les.\")\n",
    "print(\"La Logistic Regression a le meilleur Recall (79.9%), importante pour d√©tecter les dropouts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### 6.2.5 Optimisation des Hyperparam√®tres\n",
    "\n",
    "**R√©sultats de la comparaison** :\n",
    "- Les 4 mod√®les ont des performances tr√®s similaires (F1 entre 0.77 et 0.79)\n",
    "- **Logistic Regression** a le meilleur **Recall** (79.9%) - crucial pour notre objectif\n",
    "- **SVM (RBF)** a le meilleur **F1-Score** (79.0%)\n",
    "\n",
    "**Choix** : Nous allons optimiser **Logistic Regression** car :\n",
    "1. Meilleur Recall (priorit√© pour d√©tecter les dropouts)\n",
    "2. Plus interpr√©table (coefficients analysables)\n",
    "3. Plus rapide √† entra√Æner et d√©ployer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.6 GridSearchCV pour Logistic Regression\n",
    "# =============================================================================\n",
    "\n",
    "# Grille d'hyperparam√®tres pour Logistic Regression\n",
    "param_grid = {\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10, 100],  # Force de r√©gularisation (inverse)\n",
    "    \"classifier__penalty\": [\"l1\", \"l2\"],  # Type de r√©gularisation\n",
    "    \"classifier__solver\": [\"saga\"],  # Solver compatible avec l1 et l2\n",
    "    \"classifier__class_weight\": [\"balanced\"],  # Gestion du d√©s√©quilibre\n",
    "    \"classifier__max_iter\": [2000],  # Convergence\n",
    "}\n",
    "\n",
    "# Pipeline de base\n",
    "base_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# GridSearchCV avec F1-Score comme m√©trique\n",
    "print(\"üîÑ Optimisation des hyperparam√®tres en cours...\")\n",
    "print(\"   (GridSearchCV avec 5-fold cross-validation)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    base_pipeline,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Optimisation termin√©e!\")\n",
    "print(\"\\nüèÜ Meilleurs hyperparam√®tres:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param.replace('classifier__', '')}: {value}\")\n",
    "print(f\"\\nüìä Meilleur F1-Score (CV): {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.7 √âvaluation du Mod√®le Optimis√© sur le Test Set\n",
    "# =============================================================================\n",
    "\n",
    "# Le meilleur mod√®le est d√©j√† r√©entra√Æn√© sur tout le train set\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Pr√©dictions sur le test set\n",
    "y_pred_opt = best_model.predict(X_test)\n",
    "y_pred_proba_opt = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä √âVALUATION DU MOD√àLE OPTIMIS√â (Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìã Rapport de Classification:\")\n",
    "print(\"-\" * 40)\n",
    "print(classification_report(y_test, y_pred_opt, target_names=[\"Non-Dropout\", \"Dropout\"]))\n",
    "\n",
    "# M√©triques cl√©s\n",
    "recall_opt = recall_score(y_test, y_pred_opt)\n",
    "f1_opt = f1_score(y_test, y_pred_opt)\n",
    "auc_opt = roc_auc_score(y_test, y_pred_proba_opt)\n",
    "\n",
    "print(\"\\nüéØ M√©triques Prioritaires (classe Dropout):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Recall (Dropout)  : {recall_opt:.3f}\")\n",
    "print(f\"  F1-Score (Dropout): {f1_opt:.3f}\")\n",
    "print(f\"  AUC-ROC           : {auc_opt:.3f}\")\n",
    "\n",
    "# Comparaison avec le baseline\n",
    "print(\"\\nüìà Comparaison avec le Baseline:\")\n",
    "print(\"-\" * 40)\n",
    "print(\n",
    "    f\"  Recall    : {recall:.3f} ‚Üí {recall_opt:.3f} ({'+' if recall_opt >= recall else ''}{(recall_opt - recall) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  F1-Score  : {f1:.3f} ‚Üí {f1_opt:.3f} ({'+' if f1_opt >= f1 else ''}{(f1_opt - f1) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  AUC-ROC   : {auc:.3f} ‚Üí {auc_opt:.3f} ({'+' if auc_opt >= auc else ''}{(auc_opt - auc) * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.8 Visualisation Finale : Matrice de Confusion et Feature Importance\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Matrice de confusion du mod√®le optimis√©\n",
    "ax1 = axes[0]\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_opt, display_labels=[\"Non-Dropout\", \"Dropout\"])\n",
    "disp.plot(ax=ax1, cmap=\"Blues\", values_format=\"d\")\n",
    "ax1.set_title(\n",
    "    \"Matrice de Confusion\\n(Logistic Regression Optimis√©)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# 2. Feature Importance (coefficients absolus)\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Extraire les coefficients du mod√®le\n",
    "classifier = best_model.named_steps[\"classifier\"]\n",
    "coefficients = classifier.coef_[0]\n",
    "\n",
    "# R√©cup√©rer les noms des features apr√®s transformation\n",
    "feature_names = (\n",
    "    numeric_features\n",
    "    + list(\n",
    "        best_model.named_steps[\"preprocessor\"]\n",
    "        .named_transformers_[\"cat\"]\n",
    "        .get_feature_names_out(categorical_features)\n",
    "    )\n",
    "    + binary_features\n",
    ")\n",
    "\n",
    "# Cr√©er un DataFrame pour visualisation\n",
    "coef_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": feature_names,\n",
    "        \"Coefficient\": coefficients,\n",
    "        \"Abs_Coefficient\": np.abs(coefficients),\n",
    "    }\n",
    ").sort_values(\"Abs_Coefficient\", ascending=True)\n",
    "\n",
    "# Top 10 features les plus importantes\n",
    "top_features = coef_df.tail(10)\n",
    "colors = [\"#e74c3c\" if c < 0 else \"#2ecc71\" for c in top_features[\"Coefficient\"]]\n",
    "ax2.barh(top_features[\"Feature\"], top_features[\"Coefficient\"], color=colors)\n",
    "ax2.axvline(x=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "ax2.set_xlabel(\"Coefficient (impact sur le dropout)\", fontsize=11)\n",
    "ax2.set_title(\n",
    "    \"Top 10 Features les Plus Influentes\\n(Rouge = ‚Üë risque, Vert = ‚Üì risque)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpr√©tation\n",
    "print(\"\\nüí° Interpr√©tation des Coefficients:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  üî¥ Coefficient POSITIF ‚Üí Augmente le risque de dropout\")\n",
    "print(\"  üü¢ Coefficient N√âGATIF ‚Üí Diminue le risque de dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Synth√®se Phase 6.2 : Comparaison et Optimisation\n",
    "\n",
    "**R√©sultats de la comparaison (Cross-Validation 5-Fold)** :\n",
    "\n",
    "| Mod√®le | F1-Score | Recall | AUC-ROC |\n",
    "|--------|----------|--------|---------|\n",
    "| SVM (RBF) | 0.790 ¬±0.015 | 0.790 ¬±0.019 | 0.908 ¬±0.010 |\n",
    "| Logistic Regression | 0.784 ¬±0.021 | 0.799 ¬±0.024 | 0.913 ¬±0.012 |\n",
    "| Gradient Boosting | 0.783 ¬±0.013 | 0.726 ¬±0.012 | 0.911 ¬±0.013 |\n",
    "| Random Forest | 0.774 ¬±0.018 | 0.713 ¬±0.012 | 0.906 ¬±0.013 |\n",
    "\n",
    "**Choix et Optimisation** :\n",
    "- Mod√®le choisi : **Logistic Regression** (meilleur Recall, interpr√©table)\n",
    "- Hyperparam√®tres optimaux : `C=1`, `penalty='l1'`, `solver='saga'`\n",
    "\n",
    "**R√©sultats du mod√®le optimis√© (Test Set)** :\n",
    "\n",
    "| M√©trique | Baseline | Optimis√© | Changement |\n",
    "|----------|----------|----------|------------|\n",
    "| Recall (Dropout) | 83.1% | 83.1% | +0.0% |\n",
    "| F1-Score (Dropout) | 81.4% | 81.5% | +0.1% |\n",
    "| AUC-ROC | 93.1% | 93.1% | +0.0% |\n",
    "\n",
    "**Conclusion** :\n",
    "1. Les 4 mod√®les test√©s ont des performances tr√®s similaires\n",
    "2. L'optimisation des hyperparam√®tres n'a pas significativement am√©lior√© les r√©sultats\n",
    "3. Cela confirme que les **features engineered** sont le facteur cl√© de la performance\n",
    "4. Le mod√®le baseline √©tait d√©j√† proche de l'optimal gr√¢ce √† l'EDA de qualit√©\n",
    "\n",
    "**Top 5 Features les plus importantes** (Logistic Regression avec L1) :\n",
    "1. `Success_Rate_Sem2` - Taux de r√©ussite 2√®me semestre\n",
    "2. `Success_Rate_Sem1` - Taux de r√©ussite 1er semestre\n",
    "3. `Tuition fees up to date` - Frais de scolarit√© √† jour\n",
    "4. `Age_Group_36+` - √âtudiants de 36 ans et plus\n",
    "5. `Avg_Grade` - Moyenne des notes"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
